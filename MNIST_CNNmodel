import torch
from torchvision import datasets
from torchvision.transforms import ToTensor
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as data

training_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor()
)

batch_size = 64


class CNNModel(nn.Module):
    def __init__(self, batch_size):
        super(CNNModel, self).__init__()
        self.batch_size = batch_size
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3)
        self.conv2 = nn.Conv2d(in_channels=12, out_channels=4, kernel_size=3)
        self.linear1 = nn.Linear(2304, 4 * 24 * 24)
        self.linear2 = nn.Linear(4 * 24 * 24, 10)

    def forward(self, input_data):
        result = self.conv1(input_data)
        result = self.conv2(result)
        result = result.reshape(self.batch_size, -1)
        result = self.linear1(result)
        result = self.linear2(result)

        return result


if __name__ == '__main__':
    device = "cuda" if torch.cuda.is_available() else "cpu"
    training_data_loader = data.DataLoader(training_data, batch_size=batch_size, shuffle=True, drop_last=True)

    cnn_model = CNNModel(batch_size=batch_size)  # .to(device)
    cnn_model.train()
    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.1)
    loss_function = nn.BCELoss()

    epochs = 30
    for epoch in range(epochs):
        true_pred, num = 0.0, 0.0
        for x, y in training_data_loader:
            x.to(device)
            y.to(device)
            pred = cnn_model(x)
            pred = F.softmax(pred, dim=1)
            one_hot_vec = torch.zeros(size=(y.size()[0], 10), dtype=torch.float32)
            for idx in range(y.size()[0]):
                one_hot_vec[idx, y[idx]] = 1.0
            loss = loss_function(pred, one_hot_vec)
            loss.backward()
            optimizer.step()

        print(epoch,"-th epoch:")
